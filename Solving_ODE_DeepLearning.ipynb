{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograd core\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import elementwise_grad as egrad\n",
    "\n",
    "# autograd utils\n",
    "import autograd.numpy.random as npr\n",
    "from autograd.misc.flatten import flatten\n",
    "\n",
    "# scipy optimizer\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import solve_ivp # for reference\n",
    "\n",
    "#plot animation\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# A global counter for printing scipy training progress\n",
    "# https://stackoverflow.com/questions/16739065/how-to-display-progress-of-scipy-optimize-function\n",
    "# TODO: Can we improve this dirty hack?\n",
    "count = 0\n",
    "\n",
    "\n",
    "def init_weights(n_in=1, n_hidden=10, n_out=1):\n",
    "    '''\n",
    "    Initialize NN weights\n",
    "    '''\n",
    "    # TODO: more layers?\n",
    "    W1 = npr.randn(n_in, n_hidden)\n",
    "    b1 = np.zeros(n_hidden)\n",
    "    W2 = npr.randn(n_hidden, n_out)\n",
    "    b2 = np.zeros(n_out)\n",
    "    params = [W1, b1, W2, b2]\n",
    "    return params\n",
    "\n",
    "\n",
    "def predict(params, t, y0, act=np.tanh):\n",
    "    '''\n",
    "    Make NN prediction\n",
    "    '''\n",
    "    W1, b1, W2, b2 = params\n",
    "\n",
    "    a = act(np.dot(t, W1) + b1)\n",
    "    out = np.dot(a, W2) + b2  # standard NN output\n",
    "\n",
    "    # TODO: start with t0 instead of 0\n",
    "    y = y0 + t*out  # apply Lagaris et al. (1998)\n",
    "\n",
    "    return y\n",
    "   \n",
    "\n",
    "\n",
    "predict_dt = egrad(predict, argnum=1)  # element-wise grad w.r.t t\n",
    "\n",
    "\n",
    "class NNSolver(object):\n",
    "    def __init__(self, f, t, y0_list, n_hidden=10):\n",
    "        '''\n",
    "        Neural Network Solver Class\n",
    "        Parameters\n",
    "        ----------\n",
    "        f : callable\n",
    "            Right-hand side of the ODE system dy/dt = f(t, y).\n",
    "            Similar to the input for scipy.integrate.solve_ivp()\n",
    "            Important notes:\n",
    "            - Must use autograd's numpy inside f (import autograd.numpy as np)\n",
    "            - For a single ODE, should return a list of one element.\n",
    "        t : column vector, i.e. numpy array of shape (n, 1)\n",
    "            Training points\n",
    "        y0_list : a list of floating point numbers\n",
    "            Initial condition.\n",
    "            For a single ODE, should be a list of one element.\n",
    "        n_hidden : integer, optional\n",
    "            Number of hidden units of the NN\n",
    "        '''\n",
    "\n",
    "        Nvar = len(y0_list)\n",
    "        assert len(f(t[0], y0_list)) == Nvar, \\\n",
    "            'f and y0_list should have same size'\n",
    "\n",
    "        assert t.shape == (t.size, 1), 't must be a column vector'\n",
    "\n",
    "        self.Nvar = Nvar\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "        self.y0_list = y0_list\n",
    "        self.n_hidden = n_hidden\n",
    "        self.loss = 0\n",
    "        self.reset_weights()\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('Neural ODE Solver \\n'\n",
    "                'Number of equations:       {} \\n'\n",
    "                'Initial condition y0:      {} \\n'\n",
    "                'Numnber of hidden units:   {} \\n'\n",
    "                'Number of training points: {} '\n",
    "                .format(self.Nvar, self.y0_list, self.n_hidden, self.t.size)\n",
    "                )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def reset_weights(self):\n",
    "        '''reinitialize NN weights (randomly)'''\n",
    "        self.params_list = [init_weights(n_hidden=self.n_hidden)\n",
    "                            for _ in range(self.Nvar)]\n",
    "\n",
    "        flattened_params, unflat_func = flatten(self.params_list)\n",
    "        self.flattened_params = flattened_params\n",
    "        self.unflat_func = unflat_func\n",
    "\n",
    "    def loss_func(self, params_list):\n",
    "        '''Compute loss function'''\n",
    "        # params_list should be an explicit input, not from self\n",
    "\n",
    "        # some shortcut\n",
    "        y0_list = self.y0_list\n",
    "        t = self.t\n",
    "        f = self.f\n",
    "\n",
    "        y_pred_list = []\n",
    "        dydt_pred_list = []\n",
    "        for params, y0 in zip(params_list, y0_list):\n",
    "            y_pred = predict(params, t, y0)\n",
    "            dydt_pred = predict_dt(params, t, y0)\n",
    "\n",
    "            y_pred_list.append(y_pred)\n",
    "            dydt_pred_list.append(dydt_pred)\n",
    "\n",
    "        f_pred_list = f(t, y_pred_list)\n",
    "\n",
    "        loss_total = 0.0\n",
    "        for f_pred, dydt_pred in zip(f_pred_list, dydt_pred_list):\n",
    "            loss = np.mean((dydt_pred-f_pred)**2)\n",
    "            loss_total += loss\n",
    "\n",
    "        return loss_total\n",
    "\n",
    "    def loss_wrap(self, flattened_params):\n",
    "        '''Loss function that takes flattened parameters, for scipy optimizer\n",
    "        '''\n",
    "        # flattened_params should be an explicit input, not from self\n",
    "        params_list = self.unflat_func(flattened_params)\n",
    "\n",
    "        return self.loss_func(params_list)\n",
    "\n",
    "    def train(self, method='BFGS', maxiter=2000, iprint=200):\n",
    "        '''\n",
    "        Train the neural net\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method : string, optional\n",
    "            Optimization method for scipy.optimize.minimize()\n",
    "            'BFGS' should be the most robust one\n",
    "\n",
    "        maxiter : integer, optional\n",
    "            Maximum number of iterations\n",
    "\n",
    "        maxiter : integer, optional\n",
    "            Print loss per iprint step\n",
    "        '''\n",
    "        self.x = [] # updates of x during training\n",
    "\n",
    "\n",
    "\n",
    "        global count\n",
    "        global loss_arr\n",
    "        count = 0  # reset counter for next training\n",
    "        loss_arr = []\n",
    "        def print_loss(x):\n",
    "            global count\n",
    "            if count % iprint == 0:\n",
    "                print(\"iteration:\", count, \"loss: \", self.loss_wrap(x))\n",
    "            count += 1\n",
    "\n",
    "            # add new training updates to x\n",
    "            self.x.append(self.unflat_func(x))\n",
    "            loss_arr.append(self.loss_wrap(x))\n",
    "\n",
    "        opt = minimize(self.loss_wrap, x0=self.flattened_params,\n",
    "                       jac=grad(self.loss_wrap), method=method,\n",
    "                       callback=print_loss,\n",
    "                       options={'disp': True, 'maxiter': maxiter})\n",
    "\n",
    "        # update parameters\n",
    "        self.loss = loss_arr\n",
    "        self.flattened_params = opt.x\n",
    "        self.params_list = self.unflat_func(opt.x)\n",
    "\n",
    "        \n",
    "\n",
    "    def predict(self, t=None, params_list=None):\n",
    "        '''\n",
    "        Make new predicts\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : column vector, i.e. numpy array of shape (n, 1), optional\n",
    "            use training points by default\n",
    "\n",
    "        '''\n",
    "        if t is None:\n",
    "            t = self.t\n",
    "\n",
    "        if params_list is None:\n",
    "            y_pred_list = []\n",
    "            dydt_pred_list = []\n",
    "            for params, y0 in zip(self.params_list, self.y0_list):\n",
    "                y_pred = predict(params, t, y0)\n",
    "                dydt_pred = predict_dt(params, t, y0)\n",
    "\n",
    "                y_pred_list.append(y_pred.squeeze())\n",
    "                dydt_pred_list.append(dydt_pred.squeeze())\n",
    "\n",
    "            return y_pred_list, dydt_pred_list\n",
    "        \n",
    "        else:\n",
    "            y_pred_list = []\n",
    "            for params, y0 in zip(params_list, self.y0_list):\n",
    "                y_pred = predict(params, t, y0)\n",
    "\n",
    "                y_pred_list.append(y_pred.squeeze())\n",
    "\n",
    "            return y_pred_list\n",
    "    def result(self,t = None, anim = False, interval = 50, every_n_iter = 1):\n",
    "\n",
    "        '''\n",
    "        Plot trainning process at animation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : array, optional\n",
    "            evaluate at these points\n",
    "\n",
    "        anim : bool, optional\n",
    "            whether to plot animation or not, default set to False\n",
    "\n",
    "        interval : integer, optional\n",
    "            time duration between frames, in ms, default set to 50 ms\n",
    "\n",
    "        every_n_iter : integer, optional \n",
    "            plot every n iterations of the trainning process, if num of iteration if large, \n",
    "        increase every_n_iter to save computing, default set to 1, plotting all the iterations\n",
    "        '''\n",
    "\n",
    "        if t is None:\n",
    "            t = self.t\n",
    "            \n",
    "        \n",
    "        if anim:\n",
    "            \n",
    "            #training animation \n",
    "            y_train = np.array([self.predict(t = t.reshape(-1,1), params_list=x) for x in self.x])[::-every_n_iter][::-1]\n",
    "            n = y_train.shape[1]\n",
    "            \n",
    "            \n",
    "            fig, ax = plt.subplots(1,2,figsize = (16,6))\n",
    "            \n",
    "            \n",
    "            #ground truth using scipy\n",
    "            sol_cont = solve_ivp(self.f, [t.min(), t.max()], self.y0_list, method='Radau', rtol=1e-5)\n",
    "            sol_dis = solve_ivp(self.f, t_span = [t.min(), t.max()], t_eval=t, y0 = self.y0_list, method='Radau', rtol=1e-5)\n",
    "            y_diff = np.array([np.array(sol_dis.y[i]) for i in range(n)])\n",
    "            \n",
    "            \n",
    "            #set x y limit using min and max of the last iteration\n",
    "            ax[0].set_xlim((t[0], t[-1]))\n",
    "            ax[0].set_ylim((np.min(y_train[-1,:,:]), np.max(y_train[-1,:,:])))\n",
    "            \n",
    "            ax[1].set_xlim((t[0], t[-1]))\n",
    "            ax[1].set_ylim((np.min(y_train[-1,:,:] - y_diff), np.max(y_train[-1,:,:] - y_diff)))\n",
    "            \n",
    "            #plot ground truth\n",
    "            for i in range(n):\n",
    "                ax[0].plot(sol_cont.t, sol_cont.y[i], label='y{}'.format(i+1))\n",
    "                        \n",
    "            #plots of NN result\n",
    "            scatters_pred = []\n",
    "            scatters_diff = []\n",
    "            for i in range(n):\n",
    "        \n",
    "                scat1 = ax[0].scatter([], [], label = 'y_pred{}'.format(i+1))\n",
    "                scatters_pred.append(scat1)\n",
    "                \n",
    "                scat2 = ax[1].scatter([], [], label = 'y{}'.format(i+1))\n",
    "                scatters_diff.append(scat2)\n",
    "            \n",
    "            ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),fancybox=True, ncol=4)\n",
    "            ax[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),fancybox=True, ncol=4)\n",
    "            \n",
    "            ax[0].set_title(\"NN Prediction and Truth\", fontsize = 18)\n",
    "            ax[1].set_title(\"NN Prediction - Truth\", fontsize = 18)\n",
    "            # initialization function: plot the background of each frame\n",
    "            def init():\n",
    "                for k in range(n):\n",
    "                    scatters_pred[k].set_offsets(np.hstack(([], [])))\n",
    "                    scatters_diff[k].set_offsets(np.hstack(([], [])))\n",
    "                return (scatters_pred + scatters_diff)\n",
    "            \n",
    "            # animation function. This is called sequentially\n",
    "            \n",
    "            def animate(i):\n",
    "                for k in range(n):\n",
    "                    scatters_pred[k].set_offsets(np.c_[t, y_train[i,k,:]])\n",
    "                    \n",
    "                    scatters_diff[k].set_offsets(np.c_[t, y_train[i,k,:] - y_diff[k]])\n",
    "                    \n",
    "                return (scatters_pred + scatters_diff)\n",
    "            \n",
    "            # call the animator. blit=True means only re-draw the parts that have changed.\n",
    "            anim_pred = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=y_train.shape[0], interval=interval, blit=True)\n",
    "            \n",
    "            return anim_pred\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plot loss in trainning process \n",
    "        '''\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(range(len(loss_arr)), loss_arr)\n",
    "        plt.xlabel(\"Training Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss\", fontsize = 18)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using deep learning solving ODE Equation:**\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        y'(t) = F(t,y) \\\\\n",
    "        y(t_{0}) = y_{0}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**For Example:**\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        y'(x) = \\frac{-t}{y-3} \\\\\n",
    "        y(0) = 1\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "this have actual solution is $$y = 3 - \\sqrt{4-t^{2}}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, y):\n",
    "    '''\n",
    "        dy/dt = f(t, y)\n",
    "        This is f() function on the right\n",
    "    '''    \n",
    "    return [-t/(y[0] - 3)] # should be a list\n",
    "\n",
    "t = np.linspace(-2, 2, 100).reshape(-1,1)\n",
    "y0_list = [1] # should be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural ODE Solver \n",
       "Number of equations:       1 \n",
       "Initial condition y0:      [1] \n",
       "Numnber of hidden units:   10 \n",
       "Number of training points: 100 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NNSolver(f, t, y0_list)\n",
    "nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 loss:  0.15038201535353654\n",
      "iteration: 200 loss:  0.008930291466242291\n",
      "iteration: 400 loss:  0.005627283060207488\n",
      "iteration: 600 loss:  0.0049031101112924766\n",
      "iteration: 800 loss:  0.004291474660079711\n",
      "iteration: 1000 loss:  0.00328542775539429\n",
      "iteration: 1200 loss:  0.0026751891526218437\n",
      "iteration: 1400 loss:  0.0017574466602615453\n",
      "iteration: 1600 loss:  0.001338128826771397\n",
      "iteration: 1800 loss:  0.0012396343649766193\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.001186\n",
      "         Iterations: 2000\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 2312\n"
     ]
    }
   ],
   "source": [
    "nn.reset_weights()\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value of the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011864194908508716"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.loss_func(nn.params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the figure compare the predict value to actual value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f46891ecf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_list, _ = nn.predict()\n",
    "plt.plot(t, 3 - (4 - t**2)**0.5, label='true')\n",
    "plt.plot(t, y_pred_list[0], 'o', label='y1 predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the Root mean square error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error:  [0.06251362]\n"
     ]
    }
   ],
   "source": [
    "N = len(t)\n",
    "RMSE = 0\n",
    "for real, predict in zip(3 - (4 - t**2)**0.5, y_pred_list[0]):\n",
    "  RMSE += (real - predict) ** 2\n",
    "RMSE = (RMSE/N) ** (1 / 2)\n",
    "print(\"Root Mean Squared Error: \", RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
